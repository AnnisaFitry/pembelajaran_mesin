{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEMBAHASAN MATERI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi rumus normalisasi\n",
    "def norm_feature(data):\n",
    "    #data max\n",
    "    n_max = max(data)\n",
    "    #data min\n",
    "    n_min = min(data)\n",
    "    #panjang data\n",
    "    l_data = len(data)\n",
    "\n",
    "    #perulangan\n",
    "    for i in range(0, l_data):\n",
    "        #mencari normalisasi\n",
    "        data[i] = (data[i] - n_min) / (n_max - n_min)\n",
    "\n",
    "    return data\n",
    "\n",
    "# rangkuman : \n",
    "# for i in '' = adalah perulangan\n",
    "# len adalah panjang data. format = len('')\n",
    "# for i in range(0,''): = perulangan dari 0 ke ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.375, 0.125, 0.5, 1.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [10, 25, 15, 30, 50]\n",
    "\n",
    "n_data = norm_feature(data)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.11111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.45652174, 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [100, 0.01],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005]\n",
    "]\n",
    "# dengan array, len(data) hanya bisa mengakses luaran array, dari 3x2 hasilnya menjadi 3 bukan 6.\n",
    "\n",
    "# dengan numpy dapat dilihat panjang array sebenarnya.\n",
    "np_data = np.asarray(data)\n",
    "# mencari demensi array : np_data.shape\n",
    "# hasilnya (3, 2)\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_data = mm_scaler.fit_transform(data) #harus array 2 demensi\n",
    "mm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bukan array\n",
    "from statistics import mean, stdev\n",
    "def std_feature(data):\n",
    "    mean_data = mean(data)\n",
    "    std_data = stdev(data)\n",
    "    l_data = len(data)\n",
    "\n",
    "    for i in range(0, l_data):\n",
    "        data[i] = (data[i] - mean_data) / std_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7071067811865476, -0.7071067811865476]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = [100, 0.001]\n",
    "data = np.asarray(data_1)\n",
    "std_data = std_feature(data_1)\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dengan array dan len\n",
    "from statistics import mean, stdev\n",
    "def std_feature(data):\n",
    "    baris_data = len(data)\n",
    "    kolom_data = len(data[0])\n",
    "\n",
    "    for i in range(0, baris_data):\n",
    "        for j in range(0, kolom_data):\n",
    "            data[i][j] = (data[i][j] - mean(data[j])) / stdev(data[j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678, -0.71582332],\n",
       "       [ 7.95532544, -0.70710678],\n",
       "       [49.69804328, -0.59084947],\n",
       "       [87.46526419, -0.58023768],\n",
       "       [ 3.97982851, -0.57533994]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [100, 0.001],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005],\n",
    "    [88, 0.07],\n",
    "    [4, 0.1]\n",
    "]\n",
    "data = np.asarray(data)\n",
    "std_data = std_feature(data)\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dengan array dan shape\n",
    "from statistics import mean, stdev, pstdev\n",
    "def std_feature(data):\n",
    "    baris_data = data.shape[0]\n",
    "    kolom_data = data.shape[1]\n",
    "\n",
    "    for i in range(0, baris_data):\n",
    "        for j in range(0, kolom_data):\n",
    "            #sample = stdev, populasi = pstdev\n",
    "            data[i][j] = (data[i,j] - mean(data[:,j])) / stdev(data[:,j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13053908, -1.04102352],\n",
       "       [-0.58585228,  0.43340554],\n",
       "       [ 0.54596936,  0.16378374],\n",
       "       [ 1.78715622,  0.2189989 ],\n",
       "       [ 1.53764773,  0.21485145]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [100, 0.001],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005],\n",
    "    [88, 0.07],\n",
    "    [4, 0.1]\n",
    "]\n",
    "data = np.asarray(data)\n",
    "std_data = std_feature(data)\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [100, 0.001],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005],\n",
    "    [88, 0.07],\n",
    "    [4, 0.1]\n",
    "]\n",
    "data = np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26398112, -1.16389967],\n",
       "       [-1.06174414,  0.12639634],\n",
       "       [ 0.        , -1.05856939],\n",
       "       [ 0.96062565,  0.65304778],\n",
       "       [-1.16286263,  1.44302493]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dengan function sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_scaler = StandardScaler()\n",
    "std_data= ss_scaler.fit_transform(data)\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordinal\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = [\n",
    "    ['POLINEMA'],\n",
    "    ['PENS'],\n",
    "    ['PNJ'],\n",
    "    ['PNP'],\n",
    "    ['POLBAN']\n",
    "]\n",
    "ord_oe = OrdinalEncoder().fit_transform(oe)\n",
    "ord_oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oe = [\n",
    "    ['POLINEMA'],\n",
    "    ['PENS'],\n",
    "    ['PNJ'],\n",
    "    ['PNP'],\n",
    "    ['POLBAN']\n",
    "]\n",
    "ohe_oe = OneHotEncoder().fit_transform(oe)\n",
    "ohe_oe.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contoh studi kasus TF-IDF: \n",
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse', 'ran', 'saw', 'story', 'tiny'] [[0.         0.         0.         0.         0.         0.4755751\n",
      "  0.58946308 0.28088232 0.         0.         0.         0.58946308]\n",
      " [0.         0.         0.58873218 0.         0.         0.\n",
      "  0.         0.34771471 0.         0.72971837 0.         0.        ]\n",
      " [0.         0.58946308 0.         0.         0.         0.4755751\n",
      "  0.         0.28088232 0.58946308 0.         0.         0.        ]\n",
      " [0.58946308 0.         0.4755751  0.         0.58946308 0.\n",
      "  0.         0.28088232 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.67009179 0.         0.\n",
      "  0.         0.31930233 0.         0.         0.67009179 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "response = vectorizer.fit_transform(corpus)\n",
    "#print(response.toarray())\n",
    "#print(response)\n",
    "a = vectorizer.get_feature_names()\n",
    "b = response.todense()\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the house had a tiny little mouse',\n",
       " ' the cat saw the mouse',\n",
       " ' the mouse ran away from the house',\n",
       " '']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tambahan materi split\n",
    "sentence = 'the house had a tiny little mouse. the cat saw the mouse. the mouse ran away from the house.'\n",
    "stc_split = sentence.split('.')\n",
    "stc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('.txt','r')\n",
    "# stc = f.read()\n",
    "# stc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUGAS JOBSHEET 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('orange.txt', 'r')\n",
    "corpus = text.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF per kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lowertext = corpus.lower()\n",
    "# remove special characters and digits\n",
    "rschar = re.sub(\"(\\\\d|\\\\W)+\",\" \",lowertext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'earth',\n",
       " 's',\n",
       " 'dreamlands',\n",
       " 'a',\n",
       " 'bbs',\n",
       " 'for',\n",
       " 'text',\n",
       " 'file',\n",
       " 'junkies',\n",
       " 'rpgnet',\n",
       " 'gm',\n",
       " 'file',\n",
       " 'archive',\n",
       " 'site',\n",
       " 'the',\n",
       " 'five',\n",
       " 'orange',\n",
       " 'pips',\n",
       " 'when',\n",
       " 'i',\n",
       " 'glance',\n",
       " 'over',\n",
       " 'my',\n",
       " 'notes',\n",
       " 'and',\n",
       " 'records',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'cases',\n",
       " 'between',\n",
       " 'the',\n",
       " 'years',\n",
       " 'and',\n",
       " 'i',\n",
       " 'am',\n",
       " 'faced',\n",
       " 'by',\n",
       " 'so',\n",
       " 'many',\n",
       " 'which',\n",
       " 'present',\n",
       " 'strange',\n",
       " 'and',\n",
       " 'interesting',\n",
       " 'features',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'no',\n",
       " 'easy',\n",
       " 'matter',\n",
       " 'to',\n",
       " 'know',\n",
       " 'which',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'and',\n",
       " 'which',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'some',\n",
       " 'however',\n",
       " 'have',\n",
       " 'already',\n",
       " 'gained',\n",
       " 'publicity',\n",
       " 'through',\n",
       " 'the',\n",
       " 'papers',\n",
       " 'and',\n",
       " 'others',\n",
       " 'have',\n",
       " 'not',\n",
       " 'offered',\n",
       " 'a',\n",
       " 'field',\n",
       " 'for',\n",
       " 'those',\n",
       " 'peculiar',\n",
       " 'qualities',\n",
       " 'which',\n",
       " 'my',\n",
       " 'friend',\n",
       " 'possessed',\n",
       " 'in',\n",
       " 'so',\n",
       " 'high',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'and',\n",
       " 'which',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'object',\n",
       " 'of',\n",
       " 'these',\n",
       " 'papers',\n",
       " 'to',\n",
       " 'illustrate',\n",
       " 'some',\n",
       " 'too',\n",
       " 'have',\n",
       " 'baffled',\n",
       " 'his',\n",
       " 'analytical',\n",
       " 'skill',\n",
       " 'and',\n",
       " 'would',\n",
       " 'be',\n",
       " 'as',\n",
       " 'narratives',\n",
       " 'beginnings',\n",
       " 'without',\n",
       " 'an',\n",
       " 'ending',\n",
       " 'while',\n",
       " 'others',\n",
       " 'have',\n",
       " 'been',\n",
       " 'but',\n",
       " 'partially',\n",
       " 'cleared',\n",
       " 'up',\n",
       " 'and',\n",
       " 'have',\n",
       " 'their',\n",
       " 'explanations',\n",
       " 'founded',\n",
       " 'rather',\n",
       " 'upon',\n",
       " 'conjecture',\n",
       " 'and',\n",
       " 'sur',\n",
       " 'mise',\n",
       " 'than',\n",
       " 'on',\n",
       " 'that',\n",
       " 'absolute',\n",
       " 'logical',\n",
       " 'proof',\n",
       " 'which',\n",
       " 'was',\n",
       " 'so',\n",
       " 'dear',\n",
       " 'to',\n",
       " 'him',\n",
       " 'there',\n",
       " 'is',\n",
       " 'however',\n",
       " 'one',\n",
       " 'of',\n",
       " 'these',\n",
       " 'last',\n",
       " 'which',\n",
       " 'was',\n",
       " 'so',\n",
       " 'remark',\n",
       " 'able',\n",
       " 'in',\n",
       " 'its',\n",
       " 'details',\n",
       " 'and',\n",
       " 'so',\n",
       " 'startling',\n",
       " 'in',\n",
       " 'its',\n",
       " 'results',\n",
       " 'that',\n",
       " 'i',\n",
       " 'am',\n",
       " 'tempted',\n",
       " 'to',\n",
       " 'give',\n",
       " 'some',\n",
       " 'account',\n",
       " 'of',\n",
       " 'it',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'there',\n",
       " 'are',\n",
       " 'points',\n",
       " 'in',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'it',\n",
       " 'which',\n",
       " 'never',\n",
       " 'have',\n",
       " 'been',\n",
       " 'and',\n",
       " 'probably',\n",
       " 'never',\n",
       " 'will',\n",
       " 'be',\n",
       " 'entirely',\n",
       " 'cleared',\n",
       " 'up',\n",
       " 'the',\n",
       " 'year',\n",
       " 'furnished',\n",
       " 'us',\n",
       " 'with',\n",
       " 'a',\n",
       " 'long',\n",
       " 'series',\n",
       " 'of',\n",
       " 'cases',\n",
       " 'of',\n",
       " 'greater',\n",
       " 'or',\n",
       " 'less',\n",
       " 'interest',\n",
       " 'of',\n",
       " 'which',\n",
       " 'i',\n",
       " 'retain',\n",
       " 'the',\n",
       " 'records',\n",
       " 'among',\n",
       " 'my',\n",
       " 'headings',\n",
       " 'under',\n",
       " 'this',\n",
       " 'one',\n",
       " 'twelve',\n",
       " 'months',\n",
       " 'i',\n",
       " 'find',\n",
       " 'an',\n",
       " 'account',\n",
       " 'of',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'paradol',\n",
       " 'chamber',\n",
       " 'of',\n",
       " 'the',\n",
       " 'amateur',\n",
       " 'mendicant',\n",
       " 'society',\n",
       " 'who',\n",
       " 'held',\n",
       " 'a',\n",
       " 'luxurious',\n",
       " 'club',\n",
       " 'in',\n",
       " 'the',\n",
       " 'lower',\n",
       " 'vault',\n",
       " 'of',\n",
       " 'a',\n",
       " 'furniture',\n",
       " 'warehouse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'facts',\n",
       " 'connected',\n",
       " 'with',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'the',\n",
       " 'british',\n",
       " 'bark',\n",
       " 'sophy',\n",
       " 'anderson',\n",
       " 'of',\n",
       " 'the',\n",
       " 'singular',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'the',\n",
       " 'grice',\n",
       " 'patersons',\n",
       " 'in',\n",
       " 'the',\n",
       " 'island',\n",
       " 'of',\n",
       " 'uffa',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'of',\n",
       " 'the',\n",
       " 'camberwell',\n",
       " 'poisoning',\n",
       " 'case',\n",
       " 'in',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'as',\n",
       " 'may',\n",
       " 'be',\n",
       " 'remembered',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'was',\n",
       " 'able',\n",
       " 'by',\n",
       " 'winding',\n",
       " 'up',\n",
       " 'the',\n",
       " 'dead',\n",
       " 'man',\n",
       " 's',\n",
       " 'watch',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'that',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'wound',\n",
       " 'up',\n",
       " 'two',\n",
       " 'hours',\n",
       " 'before',\n",
       " 'and',\n",
       " 'that',\n",
       " 'therefore',\n",
       " 'the',\n",
       " 'deceased',\n",
       " 'had',\n",
       " 'gone',\n",
       " 'to',\n",
       " 'bed',\n",
       " 'within',\n",
       " 'that',\n",
       " 'time',\n",
       " 'a',\n",
       " 'deduction',\n",
       " 'which',\n",
       " 'was',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'importance',\n",
       " 'in',\n",
       " 'clearing',\n",
       " 'up',\n",
       " 'the',\n",
       " 'case',\n",
       " 'all',\n",
       " 'these',\n",
       " 'i',\n",
       " 'may',\n",
       " 'sketch',\n",
       " 'out',\n",
       " 'at',\n",
       " 'some',\n",
       " 'future',\n",
       " 'date',\n",
       " 'but',\n",
       " 'none',\n",
       " 'of',\n",
       " 'them',\n",
       " 'present',\n",
       " 'such',\n",
       " 'singular',\n",
       " 'features',\n",
       " 'as',\n",
       " 'the',\n",
       " 'strange',\n",
       " 'train',\n",
       " 'of',\n",
       " 'circum',\n",
       " 'stances',\n",
       " 'which',\n",
       " 'i',\n",
       " 'have',\n",
       " 'now',\n",
       " 'taken',\n",
       " 'up',\n",
       " 'my',\n",
       " 'pen',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'it',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'days',\n",
       " 'of',\n",
       " 'september',\n",
       " 'and',\n",
       " 'the',\n",
       " 'equinoctial',\n",
       " 'gales',\n",
       " 'had',\n",
       " 'set',\n",
       " 'in',\n",
       " 'with',\n",
       " 'exceptional',\n",
       " 'violence',\n",
       " 'all',\n",
       " 'day',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'had',\n",
       " 'screamed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rain',\n",
       " 'had',\n",
       " 'beaten',\n",
       " 'against',\n",
       " 'the',\n",
       " 'windows',\n",
       " 'so',\n",
       " 'that',\n",
       " 'even',\n",
       " 'here',\n",
       " 'in',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'of',\n",
       " 'great',\n",
       " 'hand',\n",
       " 'made',\n",
       " 'london',\n",
       " 'we',\n",
       " 'were',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'our',\n",
       " 'minds',\n",
       " 'for',\n",
       " 'the',\n",
       " 'instant',\n",
       " 'from',\n",
       " 'the',\n",
       " 'routine',\n",
       " 'of',\n",
       " 'life',\n",
       " 'and',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'of',\n",
       " 'those',\n",
       " 'great',\n",
       " 'elemental',\n",
       " 'forces',\n",
       " 'which',\n",
       " 'shriek',\n",
       " 'at',\n",
       " 'mankind',\n",
       " 'through',\n",
       " 'the',\n",
       " 'bars',\n",
       " 'of',\n",
       " 'his',\n",
       " 'civilization',\n",
       " 'like',\n",
       " 'untamed',\n",
       " 'beasts',\n",
       " 'in',\n",
       " 'a',\n",
       " 'cage',\n",
       " 'as',\n",
       " 'evening',\n",
       " 'drew',\n",
       " 'in',\n",
       " 'the',\n",
       " 'storm',\n",
       " 'grew',\n",
       " 'higher',\n",
       " 'and',\n",
       " 'louder',\n",
       " 'and',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'cried',\n",
       " 'and',\n",
       " 'sobbed',\n",
       " 'like',\n",
       " 'a',\n",
       " 'child',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chimney',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'sat',\n",
       " 'moodily',\n",
       " 'at',\n",
       " 'one',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fireplace',\n",
       " 'cross',\n",
       " 'indexing',\n",
       " 'his',\n",
       " 'records',\n",
       " 'of',\n",
       " 'crime',\n",
       " 'while',\n",
       " 'i',\n",
       " 'at',\n",
       " 'the',\n",
       " 'other',\n",
       " 'was',\n",
       " 'deep',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'clark',\n",
       " 'russell',\n",
       " 's',\n",
       " 'fine',\n",
       " 'sea',\n",
       " 'stories',\n",
       " 'until',\n",
       " 'the',\n",
       " 'howl',\n",
       " 'of',\n",
       " 'the',\n",
       " 'gale',\n",
       " 'from',\n",
       " 'without',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'blend',\n",
       " 'with',\n",
       " 'the',\n",
       " 'text',\n",
       " 'and',\n",
       " 'the',\n",
       " 'splash',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rain',\n",
       " 'to',\n",
       " 'lengthen',\n",
       " 'out',\n",
       " 'into',\n",
       " 'the',\n",
       " 'long',\n",
       " 'swash',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'waves',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'was',\n",
       " 'on',\n",
       " 'a',\n",
       " 'visit',\n",
       " 'to',\n",
       " 'her',\n",
       " 'mother',\n",
       " 's',\n",
       " 'and',\n",
       " 'for',\n",
       " 'a',\n",
       " 'few',\n",
       " 'days',\n",
       " 'i',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dweller',\n",
       " 'once',\n",
       " 'more',\n",
       " 'in',\n",
       " 'my',\n",
       " 'old',\n",
       " 'quarters',\n",
       " 'at',\n",
       " 'baker',\n",
       " 'street',\n",
       " 'why',\n",
       " 'said',\n",
       " 'i',\n",
       " 'glancing',\n",
       " 'up',\n",
       " 'at',\n",
       " 'my',\n",
       " 'companion',\n",
       " 'that',\n",
       " 'was',\n",
       " 'surely',\n",
       " 'the',\n",
       " 'bell',\n",
       " 'who',\n",
       " 'could',\n",
       " 'come',\n",
       " 'to',\n",
       " 'night',\n",
       " 'some',\n",
       " 'friend',\n",
       " 'of',\n",
       " 'yours',\n",
       " 'perhaps',\n",
       " 'except',\n",
       " 'yourself',\n",
       " 'i',\n",
       " 'have',\n",
       " 'none',\n",
       " 'he',\n",
       " 'answered',\n",
       " 'i',\n",
       " 'do',\n",
       " 'not',\n",
       " 'encourage',\n",
       " 'visitors',\n",
       " 'a',\n",
       " 'client',\n",
       " 'then',\n",
       " 'if',\n",
       " 'so',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'serious',\n",
       " 'case',\n",
       " 'nothing',\n",
       " 'less',\n",
       " 'would',\n",
       " 'bring',\n",
       " 'a',\n",
       " 'man',\n",
       " 'out',\n",
       " 'on',\n",
       " 'such',\n",
       " 'a',\n",
       " 'day',\n",
       " 'and',\n",
       " 'at',\n",
       " 'such',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'but',\n",
       " 'i',\n",
       " 'take',\n",
       " 'it',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'more',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'be',\n",
       " 'some',\n",
       " 'crony',\n",
       " 'of',\n",
       " 'the',\n",
       " 'landlady',\n",
       " 's',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'was',\n",
       " 'wrong',\n",
       " 'in',\n",
       " 'his',\n",
       " 'conjecture',\n",
       " 'however',\n",
       " 'for',\n",
       " 'there',\n",
       " 'came',\n",
       " 'a',\n",
       " 'step',\n",
       " 'in',\n",
       " 'the',\n",
       " 'passage',\n",
       " 'and',\n",
       " 'a',\n",
       " 'tapping',\n",
       " 'at',\n",
       " 'the',\n",
       " 'door',\n",
       " 'he',\n",
       " 'stretched',\n",
       " 'out',\n",
       " 'his',\n",
       " 'long',\n",
       " 'arm',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'lamp',\n",
       " 'away',\n",
       " 'from',\n",
       " 'himself',\n",
       " 'and',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'vacant',\n",
       " 'chair',\n",
       " 'upon',\n",
       " 'which',\n",
       " 'a',\n",
       " 'newcomer',\n",
       " 'must',\n",
       " 'sit',\n",
       " 'come',\n",
       " 'in',\n",
       " 'said',\n",
       " 'he',\n",
       " 'the',\n",
       " 'man',\n",
       " 'who',\n",
       " 'entered',\n",
       " 'was',\n",
       " 'young',\n",
       " 'some',\n",
       " 'two',\n",
       " 'and',\n",
       " 'twenty',\n",
       " 'at',\n",
       " 'the',\n",
       " 'outside',\n",
       " 'well',\n",
       " 'groomed',\n",
       " 'and',\n",
       " 'trimly',\n",
       " 'clad',\n",
       " 'with',\n",
       " 'something',\n",
       " 'of',\n",
       " 'refine',\n",
       " 'ment',\n",
       " 'and',\n",
       " 'delicacy',\n",
       " 'in',\n",
       " 'his',\n",
       " 'bearing',\n",
       " 'the',\n",
       " 'streaming',\n",
       " 'umbrella',\n",
       " 'which',\n",
       " 'he',\n",
       " 'held',\n",
       " 'in',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'and',\n",
       " 'his',\n",
       " 'long',\n",
       " 'shining',\n",
       " 'waterproof',\n",
       " 'told',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fierce',\n",
       " 'weather',\n",
       " 'through',\n",
       " 'which',\n",
       " 'he',\n",
       " 'had',\n",
       " 'come',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'about',\n",
       " 'him',\n",
       " 'anxiously',\n",
       " 'in',\n",
       " 'the',\n",
       " 'glare',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lamp',\n",
       " 'and',\n",
       " 'i',\n",
       " 'could',\n",
       " 'see',\n",
       " 'that',\n",
       " 'his',\n",
       " 'face',\n",
       " 'was',\n",
       " 'pale',\n",
       " 'and',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'heavy',\n",
       " 'like',\n",
       " 'those',\n",
       " 'of',\n",
       " 'a',\n",
       " 'man',\n",
       " 'who',\n",
       " 'is',\n",
       " 'weighed',\n",
       " 'down',\n",
       " 'with',\n",
       " 'some',\n",
       " 'great',\n",
       " 'anxiety',\n",
       " 'l',\n",
       " 'owe',\n",
       " 'you',\n",
       " 'an',\n",
       " 'apology',\n",
       " 'he',\n",
       " 'said',\n",
       " 'raising',\n",
       " 'his',\n",
       " 'golden',\n",
       " 'pince',\n",
       " 'nez',\n",
       " 'to',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'i',\n",
       " 'trust',\n",
       " 'that',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'intruding',\n",
       " 'i',\n",
       " 'fear',\n",
       " 'that',\n",
       " 'i',\n",
       " 'have',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'traces',\n",
       " 'of',\n",
       " 'the',\n",
       " 'storm',\n",
       " 'and',\n",
       " 'rain',\n",
       " 'into',\n",
       " 'your',\n",
       " 'snug',\n",
       " 'chamber',\n",
       " 'give',\n",
       " 'me',\n",
       " 'your',\n",
       " 'coat',\n",
       " 'and',\n",
       " 'umbrella',\n",
       " 'said',\n",
       " 'holmes',\n",
       " 'they',\n",
       " 'may',\n",
       " 'rest',\n",
       " 'here',\n",
       " 'on',\n",
       " 'the',\n",
       " 'hook',\n",
       " 'and',\n",
       " 'will',\n",
       " 'be',\n",
       " 'dry',\n",
       " 'presently',\n",
       " 'you',\n",
       " 'have',\n",
       " 'come',\n",
       " 'up',\n",
       " 'from',\n",
       " 'the',\n",
       " 'south',\n",
       " 'west',\n",
       " 'i',\n",
       " 'see',\n",
       " 'yes',\n",
       " 'from',\n",
       " 'horsham',\n",
       " 'that',\n",
       " 'clay',\n",
       " 'and',\n",
       " 'chalk',\n",
       " 'mixture',\n",
       " 'which',\n",
       " 'i',\n",
       " 'see',\n",
       " 'upon',\n",
       " 'your',\n",
       " 'toe',\n",
       " 'caps',\n",
       " 'is',\n",
       " 'quite',\n",
       " 'distinctive',\n",
       " 'i',\n",
       " 'have',\n",
       " 'come',\n",
       " 'for',\n",
       " 'advice',\n",
       " 'that',\n",
       " 'is',\n",
       " 'easily',\n",
       " 'got',\n",
       " 'and',\n",
       " 'help',\n",
       " 'that',\n",
       " 'is',\n",
       " 'not',\n",
       " 'always',\n",
       " 'so',\n",
       " 'easy',\n",
       " 'i',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'of',\n",
       " 'you',\n",
       " 'mr',\n",
       " 'holmes',\n",
       " 'i',\n",
       " 'heard',\n",
       " 'from',\n",
       " 'major',\n",
       " 'prendergast',\n",
       " 'how',\n",
       " 'you',\n",
       " 'saved',\n",
       " 'him',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tankerville',\n",
       " 'club',\n",
       " 'scandal',\n",
       " 'ah',\n",
       " 'of',\n",
       " 'course',\n",
       " 'he',\n",
       " 'was',\n",
       " 'wrongfully',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'cheating',\n",
       " 'at',\n",
       " 'cards',\n",
       " 'he',\n",
       " 'said',\n",
       " 'that',\n",
       " 'you',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'anything',\n",
       " 'he',\n",
       " 'said',\n",
       " 'too',\n",
       " 'much',\n",
       " 'that',\n",
       " 'you',\n",
       " 'are',\n",
       " 'never',\n",
       " 'beaten',\n",
       " 'i',\n",
       " 'have',\n",
       " 'been',\n",
       " 'beaten',\n",
       " 'four',\n",
       " 'times',\n",
       " 'three',\n",
       " 'times',\n",
       " 'by',\n",
       " 'men',\n",
       " 'and',\n",
       " 'once',\n",
       " 'by',\n",
       " 'a',\n",
       " 'woman',\n",
       " 'but',\n",
       " 'what',\n",
       " 'is',\n",
       " 'that',\n",
       " 'compared',\n",
       " 'with',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'your',\n",
       " 'successes',\n",
       " 'it',\n",
       " 'is',\n",
       " 'true',\n",
       " 'that',\n",
       " 'i',\n",
       " 'have',\n",
       " 'been',\n",
       " 'generally',\n",
       " 'successful',\n",
       " 'then',\n",
       " 'you',\n",
       " 'may',\n",
       " 'be',\n",
       " 'so',\n",
       " 'with',\n",
       " 'me',\n",
       " 'i',\n",
       " 'beg',\n",
       " 'that',\n",
       " 'you',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = rschar.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abjure</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidental</th>\n",
       "      <th>accidents</th>\n",
       "      <th>accomplishment</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrongfully</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>youngster</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7432 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abjure  able  abound  absence  absolute  abuse  accident  accidental  \\\n",
       "0        0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "1        0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "2        0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "3        0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "4        0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "...      ...   ...     ...      ...       ...    ...       ...         ...   \n",
       "7427     0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "7428     0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "7429     0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "7430     0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "7431     0.0   0.0     0.0      0.0       0.0    0.0       0.0         0.0   \n",
       "\n",
       "      accidents  accomplishment  ...  wrong  wrongfully  wrote  year  years  \\\n",
       "0           0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "1           0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "2           0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "3           0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "4           0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "...         ...             ...  ...    ...         ...    ...   ...    ...   \n",
       "7427        0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "7428        0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "7429        0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "7430        0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "7431        0.0             0.0  ...    0.0         0.0    0.0   0.0    0.0   \n",
       "\n",
       "      yes  yesterday  young  youngster  zero  \n",
       "0     0.0        0.0    0.0        0.0   0.0  \n",
       "1     0.0        0.0    0.0        0.0   0.0  \n",
       "2     0.0        0.0    0.0        0.0   0.0  \n",
       "3     0.0        0.0    0.0        0.0   0.0  \n",
       "4     0.0        0.0    0.0        0.0   0.0  \n",
       "...   ...        ...    ...        ...   ...  \n",
       "7427  0.0        0.0    0.0        0.0   0.0  \n",
       "7428  0.0        0.0    0.0        0.0   0.0  \n",
       "7429  0.0        0.0    0.0        0.0   0.0  \n",
       "7430  0.0        0.0    0.0        0.0   0.0  \n",
       "7431  0.0        0.0    0.0        0.0   0.0  \n",
       "\n",
       "[7432 rows x 1572 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(words)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns = feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "Name: earth, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc digunakan untuk mengakses data berdasarkan label (nama kolom).\n",
    "df.loc[0:2, 'earth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driving</th>\n",
       "      <th>drove</th>\n",
       "      <th>drunken</th>\n",
       "      <th>dry</th>\n",
       "      <th>dundee</th>\n",
       "      <th>duty</th>\n",
       "      <th>dweller</th>\n",
       "      <th>early</th>\n",
       "      <th>earth</th>\n",
       "      <th>ease</th>\n",
       "      <th>easily</th>\n",
       "      <th>east</th>\n",
       "      <th>easterly</th>\n",
       "      <th>eastern</th>\n",
       "      <th>easy</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>edge</th>\n",
       "      <th>edged</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driving  drove  drunken  dry  dundee  duty  dweller  early  earth  ease  \\\n",
       "0      0.0    0.0      0.0  0.0     0.0   0.0      0.0    0.0    0.0   0.0   \n",
       "1      0.0    0.0      0.0  0.0     0.0   0.0      0.0    0.0    1.0   0.0   \n",
       "\n",
       "   easily  east  easterly  eastern  easy  eccentric  eccentricity  edge  \\\n",
       "0     0.0   0.0       0.0      0.0   0.0        0.0           0.0   0.0   \n",
       "1     0.0   0.0       0.0      0.0   0.0        0.0           0.0   0.0   \n",
       "\n",
       "   edged  education  \n",
       "0    0.0        0.0  \n",
       "1    0.0        0.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iloc digunakan untuk mengakses data berdasarkan posisi.\n",
    "df.iloc[0:2, 380:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abjure</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidental</th>\n",
       "      <th>accidents</th>\n",
       "      <th>accomplishment</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrongfully</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>youngster</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "      <td>7432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.030678</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.036659</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            abjure         able       abound      absence     absolute  \\\n",
       "count  7432.000000  7432.000000  7432.000000  7432.000000  7432.000000   \n",
       "mean      0.000135     0.000942     0.000135     0.000135     0.000135   \n",
       "std       0.011600     0.030678     0.011600     0.011600     0.011600   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             abuse     accident   accidental    accidents  accomplishment  \\\n",
       "count  7432.000000  7432.000000  7432.000000  7432.000000     7432.000000   \n",
       "mean      0.000135     0.000135     0.000135     0.000135        0.000135   \n",
       "std       0.011600     0.011600     0.011600     0.011600        0.011600   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "       ...        wrong   wrongfully        wrote         year        years  \\\n",
       "count  ...  7432.000000  7432.000000  7432.000000  7432.000000  7432.000000   \n",
       "mean   ...     0.000135     0.000135     0.000135     0.000673     0.000807   \n",
       "std    ...     0.011600     0.011600     0.011600     0.025931     0.028404   \n",
       "min    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    ...     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               yes    yesterday        young    youngster         zero  \n",
       "count  7432.000000  7432.000000  7432.000000  7432.000000  7432.000000  \n",
       "mean      0.000538     0.000135     0.001346     0.000135     0.000135  \n",
       "std       0.023195     0.011600     0.036659     0.011600     0.011600  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 1572 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe() digunakan untuk menampilkan deskriptif statistik data. Hanya kolom yang bertipe numerik yang akan ditampilkan statistiknya.\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9184ab2ddc8f659798f178a578ee96d80d45d843af6eb73aeed9e972c7bc8f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
